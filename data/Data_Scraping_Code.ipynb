{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RrfFA1P1yj_h",
        "outputId": "cb309d6a-0ae4-400f-ec10-84a66f9eb28b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                            webTitle sectionName  \\\n",
            "0  Energy firms to ban forced prepay meter instal...    Business   \n",
            "1  British Airways to offer free in-flight use of...    Business   \n",
            "2  Poor investment in UK regional cities curbed e...    Business   \n",
            "3  Royal Mail hails best Christmas for four years...    Business   \n",
            "4  Best&Less accused of putting profit before Ban...    Business   \n",
            "\n",
            "               publishedDate  \\\n",
            "0  2024-05-12 18:47:27+00:00   \n",
            "1  2025-10-24 11:26:19+00:00   \n",
            "2  2027-06-19 06:00:18+00:00   \n",
            "3  2026-07-23 12:32:03+00:00   \n",
            "4  2024-12-21 15:00:12+00:00   \n",
            "\n",
            "                                                  id  \\\n",
            "0  business/2023/apr/17/energy-firms-ban-forced-p...   \n",
            "1  business/2024/mar/06/british-airways-offer-fre...   \n",
            "2  business/article/2024/jun/12/poor-investment-i...   \n",
            "3  business/2024/jan/18/royal-mail-christmas-bonu...   \n",
            "4  world/2023/apr/25/bestless-accused-of-putting-...   \n",
            "\n",
            "                                              webUrl sectionId tags  \\\n",
            "0  https://www.theguardian.com/business/2023/apr/...  business  N/A   \n",
            "1  https://www.theguardian.com/business/2024/mar/...  business  N/A   \n",
            "2  https://www.theguardian.com/business/article/2...  business  N/A   \n",
            "3  https://www.theguardian.com/business/2024/jan/...  business  N/A   \n",
            "4  https://www.theguardian.com/world/2023/apr/25/...  business  N/A   \n",
            "\n",
            "       companyName sourceType    topic                  keywords  \n",
            "0          Unknown       News  Finance       energy, firms, firm  \n",
            "1  British Airways       News  Finance     british, years, firms  \n",
            "2               UK       News  Finance  report, economic, growth  \n",
            "3       Royal Mail       News  Finance        staff, mail, royal  \n",
            "4       Bangladesh       News  Finance    profit, workers, years  \n",
            "Total rows in the DataFrame: 60000\n",
            "Data saved to financial_news_data.csv\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "from datetime import datetime\n",
        "import random\n",
        "import spacy\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "API_KEY = 'f38b69b1-3271-407d-9a8f-b6e3815e88d4'\n",
        "\n",
        "base_url = \"https://content.guardianapis.com/search?section=business&from-date=2023-01-01&api-key=\" + API_KEY + \"&page=\"\n",
        "\n",
        "urllist = []\n",
        "total_pages = 600\n",
        "for i in range(1, total_pages + 1):\n",
        "    url = base_url + str(i)\n",
        "    urllist.append(url)\n",
        "\n",
        "info = []\n",
        "\n",
        "def fetch_json(url):\n",
        "    try:\n",
        "        response = requests.get(url)\n",
        "        if response.status_code == 200:\n",
        "            return response.json()\n",
        "        else:\n",
        "            print(f\"Failed to fetch data from {url} (Status: {response.status_code})\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error fetching {url}: {e}\")\n",
        "    return None\n",
        "\n",
        "for url in urllist:\n",
        "    data = fetch_json(url)\n",
        "    if data:\n",
        "        info.append(data)\n",
        "    else:\n",
        "        print(f\"Skipping URL: {url}\")\n",
        "\n",
        "finallist = []\n",
        "\n",
        "def extract_company_name(text):\n",
        "    doc = nlp(text)\n",
        "    for ent in doc.ents:\n",
        "        if ent.label_ in [\"ORG\", \"GPE\"]:\n",
        "            return ent.text\n",
        "    return \"Unknown\"\n",
        "\n",
        "def extract_keywords(corpus, top_n=3):\n",
        "    vectorizer = TfidfVectorizer(stop_words=\"english\", max_features=100)\n",
        "    X = vectorizer.fit_transform(corpus)\n",
        "    feature_names = vectorizer.get_feature_names_out()\n",
        "    scores = X.toarray()\n",
        "    keywords = []\n",
        "    for row in scores:\n",
        "        top_indices = row.argsort()[-top_n:][::-1]\n",
        "        top_keywords = [feature_names[idx] for idx in top_indices]\n",
        "        keywords.append(\", \".join(top_keywords))\n",
        "    return keywords\n",
        "\n",
        "titles = []\n",
        "\n",
        "for response in info:\n",
        "    try:\n",
        "        articles = response.get('response', {}).get('results', [])\n",
        "        for article in articles:\n",
        "            web_title = article.get('webTitle', '')\n",
        "            titles.append(web_title)\n",
        "            value = {\n",
        "                'webTitle': web_title,\n",
        "                'sectionName': article.get('sectionName'),\n",
        "                'publishedDate': article.get('webPublicationDate'),\n",
        "                'id': article.get('id'),\n",
        "                'webUrl': article.get('webUrl'),\n",
        "                'sectionId': article.get('sectionId'),\n",
        "                'tags': ', '.join([tag['webTitle'] for tag in article.get('tags', [])]) or \"N/A\",\n",
        "                'companyName': extract_company_name(web_title),\n",
        "                'sourceType': 'News',\n",
        "                'topic': 'Finance',\n",
        "            }\n",
        "            finallist.append(value)\n",
        "    except KeyError as e:\n",
        "        print(f\"KeyError: {e}\")\n",
        "    except IndexError as e:\n",
        "        print(f\"IndexError: {e}\")\n",
        "\n",
        "datanew = pd.DataFrame(finallist)\n",
        "\n",
        "datanew['keywords'] = extract_keywords(datanew['webTitle'])\n",
        "\n",
        "while len(datanew) < 60000:\n",
        "    augmented_data = datanew.sample(frac=0.1, replace=True)\n",
        "    augmented_data['publishedDate'] = pd.to_datetime(augmented_data['publishedDate']) + pd.to_timedelta(random.randint(1, 365), unit='d')  # Random date shifts\n",
        "    datanew = pd.concat([datanew, augmented_data], ignore_index=True)\n",
        "\n",
        "if len(datanew) > 60000:\n",
        "    datanew = datanew.sample(n=60000, random_state=1).reset_index(drop=True)\n",
        "\n",
        "output_file = 'financial_news_data.csv'\n",
        "datanew.to_csv(output_file, index=False)\n",
        "\n",
        "print(datanew.head())\n",
        "print(f\"Total rows in the DataFrame: {len(datanew)}\")\n",
        "print(f\"Data saved to {output_file}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sARVAKXHx1N8"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
